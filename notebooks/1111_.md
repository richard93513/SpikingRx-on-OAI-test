# 11/11 Final Report Log
Subject: SpikingRx Model Module Development Progress (LIF â†’ Conv â†’ Norm â†’ SEW Block)

---

## 1. LIF Module (lif_neuron.py)

### Module Description
LIF (Leaky Integrate-and-Fire) is the core neuron module in the SpikingRx architecture.
Its function is to simulate biological neuronal temporal dynamics and convert continuous-valued inputs
(from Conv + Norm) into a time-series spike sequence (0/1).

### Position in SEW Block
Conv â†’ Norm â†’ **LIF** â†’ Shortcut

---

## Code

```python
# src/models/lif_neuron.py

# --------------------------------------------------------
# æ¨¡çµ„ä½ç½®å°æ‡‰ï¼šSpikingRx â†’ SEW-ResNet block â†’ LIF ç¥ç¶“å…ƒ
# --------------------------------------------------------
# é€™å€‹æª”æ¡ˆ lif_neuron.py å°æ‡‰ SpikingRx è«–æ–‡æ¶æ§‹ä¸­çš„ã€Œspiking activation å±¤ã€
# åœ¨ SEW-ResNet block ä¸­çš„æµç¨‹ç‚ºï¼š
# Conv â†’ Norm â†’ LIF(spikeç”¢ç”Ÿ) â†’ Shortcut â†’ ä¸‹ä¸€å±¤
# LIF æ˜¯åœ¨é€™è£¡æŠŠé€£çºŒå€¼ feature è½‰æˆ 0/1 çš„ spikeã€‚
# --------------------------------------------------------

import torch                    # åŒ¯å…¥ PyTorch ä¸»å‡½å¼åº«
import torch.nn as nn           # åŒ¯å…¥ç¥ç¶“ç¶²è·¯æ¨¡çµ„ (nn.Module, Parameter)
# --------------------------------------------------------
# SpikingRx: å¯¦éš›è¨“ç·´èˆ‡æ¨è«–éƒ½æ˜¯åŸºæ–¼ PyTorch å¯¦ä½œçš„ LIF æ¨¡å‹
# --------------------------------------------------------

# ========================================================
# ä¸€ã€Triangular Surrogate Gradientï¼ˆä¸‰è§’å½¢æ›¿ä»£æ¢¯åº¦ï¼‰
# ========================================================
# é€™æ˜¯è«–æ–‡ä¸­æ˜ç¢ºä½¿ç”¨çš„ surrogate gradientï¼š
# Ïƒâ€²(x) = max(0, 1 - |x|/a) / a
# åªåœ¨ |x| < a ç¯„åœå…§æœ‰æ¢¯åº¦ï¼Œå…¶ä»–åœ°æ–¹ç‚º 0ã€‚
# å¥½è™•ï¼šé¿å…æ¢¯åº¦çˆ†ç‚¸ï¼Œä¸”åªåœ¨é–¾å€¼é™„è¿‘æ›´æ–°ã€‚
# ========================================================

class TriangularSurrogate(torch.autograd.Function):        # å®šç¾©è‡ªè¨‚ autograd å‡½å¼ï¼ˆå‰å‘+åå‘ï¼‰
    @staticmethod
    def forward(ctx, x, a=1.0):                            # forward: å‰å‘å‚³éï¼Œctx å¯ç”¨ä¾†å­˜å€¼
        ctx.save_for_backward(x)                           # æŠŠ xï¼ˆè†œé›»ä½æ¸›é–¾å€¼ï¼‰å­˜èµ·ä¾†ï¼Œåå‘æ™‚ç”¨
        ctx.a = a                                          # æŠŠåƒæ•¸ a å­˜èµ·ä¾†ï¼ˆæ§åˆ¶æ¢¯åº¦ç¯„åœï¼‰
        return (x >= 0).to(x.dtype)                        # Heaviside stepï¼šè‹¥ Uâ‰¥Î¸ è¼¸å‡º1ï¼Œå¦å‰‡0
        # âœ³ï¸ é€™ä¸€æ­¥å°æ‡‰ SpikingRx çš„ã€ŒS[t] = H(U[t] - Î¸)ã€
        # âœ³ï¸ forward å›å‚³çš„å°±æ˜¯é€™å€‹æ™‚é–“æ­¥çš„ spikeï¼ˆäºŒå€¼ 0/1ï¼‰

    @staticmethod
    def backward(ctx, grad_output):                        # backward: åå‘å‚³éæ™‚å‘¼å«
        (x,) = ctx.saved_tensors                           # å–å‡º forward æ™‚å­˜çš„ x
        a = ctx.a                                          # å–å‡ºå¹³æ»‘æ§åˆ¶åƒæ•¸ a
        grad_input = grad_output.clone()                   # è¤‡è£½ä¸Šæ¸¸æ¢¯åº¦ (âˆ‚L/âˆ‚S)

        # Triangular surrogate å…¬å¼ï¼šÏƒâ€²(x) = max(0, 1 - |x|/a) / a
        mask = (x.abs() < a).to(x.dtype)                   # åªåœ¨ |x| < a çš„ç¯„åœå…§ä¿ç•™æ¢¯åº¦
        grad = grad_input * (1 - x.abs() / a) * mask / a   # è¨ˆç®—æ›¿ä»£æ¢¯åº¦ï¼ˆåœ¨é–¾å€¼é™„è¿‘éé›¶ï¼‰
        # âœ³ï¸ é€™è£¡å°±æ˜¯ surrogate gradient çš„ç²¾é«“ï¼š
        #    spike é›–ç„¶ä¸å¯å¾®ï¼Œä½†é€™è£¡çµ¦å®ƒä¸€å€‹ã€Œå€’Vå½¢ã€çš„å‡æ¢¯åº¦è®“å®ƒèƒ½å­¸ã€‚
        return grad, None                                  # å›å‚³å°æ‡‰æ–¼ (x, a) çš„æ¢¯åº¦ï¼ˆaä¸éœ€è¦æ¢¯åº¦ï¼‰

# --------------------------------------------------------
# spike_fn æ˜¯åŒ…è£å¥½çš„æ–¹ä¾¿å‡½å¼
# è®“å¤–éƒ¨ç›´æ¥å‘¼å« spike_fn(U - Î¸) ç”¢ç”Ÿ spikeã€‚
# --------------------------------------------------------
def spike_fn(x, a=1.0):
    return TriangularSurrogate.apply(x, a)                 # ä½¿ç”¨ä¸Šé¢å®šç¾©çš„è‡ªè¨‚ autograd function


# ========================================================
# äºŒã€LIF æ¨¡å‹ (Leaky Integrate-and-Fire Neuron)
# ========================================================
# åœ¨ SpikingRx çš„ SEW-ResNet block ä¸­ï¼Œ
# LIF æ˜¯ã€Œspiking activationã€ï¼š
#   Conv è¼¸å‡ºé€£çºŒå€¼ç‰¹å¾µ â†’ ç¶“ Norm æ­£è¦åŒ– â†’ å‚³å…¥ LIF
#   LIF æœƒéš¨æ™‚é–“æ­¥ t ç´¯ç©è†œé›»ä½ï¼Œè¶…éé–¾å€¼ Î¸ æ™‚ç™¼å‡º spikeã€‚
# ========================================================

class LIF(nn.Module):                                      # å®šç¾©ä¸€å€‹ç¥ç¶“å…ƒæ¨¡çµ„
    """
    ç¬¦åˆ SpikingRx è«–æ–‡çš„é›¢æ•£æ™‚é–“ LIF æ¨¡å‹ï¼š
      U[t] = Î²U[tâˆ’1] + (1âˆ’Î²)I[t]             â† è†œé›»ä½ç©åˆ†ï¼ˆleakyï¼‰
      S[t] = spike_fn(U[t] âˆ’ Î¸)               â† åˆ¤æ–·æ˜¯å¦è·¨é–¾ç”¢ç”Ÿspike
      U[t] = U[t] âˆ’ S[t]Î¸                     â† ç™¼æ³¡å¾Œ soft reset
    """

    def __init__(self, beta=0.9, theta=1.0, learn_beta=False):
        super().__init__()                    # åˆå§‹åŒ–çˆ¶é¡åˆ¥
        if learn_beta:
            # è‹¥ learn_beta=Trueï¼Œè®“ Î² æˆç‚ºå¯è¨“ç·´åƒæ•¸ï¼ˆä½†è«–æ–‡ä¸­å›ºå®šÎ²=0.9ï¼‰
            self.beta = nn.Parameter(torch.tensor(float(beta)))
        else:
            # å¦å‰‡è¨»å†Šæˆ bufferï¼ˆåƒæ•¸å›ºå®šï¼Œä½†æœƒéš¨ model.to(device) ä¸€èµ·ç§»å‹•ï¼‰
            self.register_buffer("beta", torch.tensor(float(beta)))

        # é–¾å€¼ Î¸ï¼šç•¶è†œé›»ä½è¶…éæ­¤å€¼æ™‚ç”¢ç”Ÿspike
        self.register_buffer("theta", torch.tensor(float(theta)))

    # ----------------------------------------------------
    # forward: LIF çš„ä¸»è¦æ™‚åºé‹ç®—
    # I: [B, T, C, H, W] ï¼ˆå·ç©è¼¸å‡ºï¼‰æˆ– [B, T, D]ï¼ˆå…¨é€£æ¥è¼¸å‡ºï¼‰
    # å°æ‡‰ SpikingRx è«–æ–‡ä¸­ï¼šæ¯ä¸€å€‹ block éƒ½åœ¨ T å€‹æ™‚é–“æ­¥ä¸Šé‹ä½œã€‚
    # ----------------------------------------------------
    def forward(self, I):
        if I.dim() == 5:                                     # [B, T, C, H, W]
            B, T, C, H, W = I.shape
            U = I.new_zeros((B, C, H, W))                    # åˆå§‹è†œé›»ä½ U[0]=0
            out_spikes = []                                  # ç”¨ä¾†æ”¶é›†æ¯å€‹æ™‚é–“æ­¥çš„ spike
            for t in range(T):                               # æ™‚é–“å±•é–‹ï¼šæ¨¡æ“¬ T å€‹æ™‚é–“æ­¥
                It = I[:, t]                                 # å–ç¬¬ t å€‹æ™‚é–“æ­¥çš„è¼¸å…¥
                U = self.beta * U + (1 - self.beta) * It     # æ›´æ–°è†œé›»ä½ï¼ˆleaky integrationï¼‰
                # âœ³ï¸ å°æ‡‰è«–æ–‡å…¬å¼ï¼šU[t] = Î²U[tâˆ’1] + (1âˆ’Î²)I[t]

                S = spike_fn(U - self.theta)                 # åˆ¤æ–·æ˜¯å¦æ”¾é›»ï¼ˆè·¨é–¾å€¼ï¼‰
                # âœ³ï¸ å°æ‡‰è«–æ–‡ï¼šS[t] = H(U[t] âˆ’ Î¸)
                # âœ³ï¸ forward æ™‚é€™è£¡æ˜¯ 0/1ï¼Œä½† backward æ™‚ç”¨ triangular surrogate å‚³æ¢¯åº¦

                U = U - S * self.theta                       # æ”¾é›»å¾Œ soft reset
                # âœ³ï¸ å°æ‡‰è«–æ–‡ï¼šU[t] = U[t] âˆ’ S[t]Î¸
                # âœ³ï¸ è‹¥æ”¾é›» S=1 â†’ æ¸›æ‰ Î¸ï¼›è‹¥æ²’æ”¾é›» S=0 â†’ ä¿ç•™ç›®å‰è†œé›»ä½ã€‚

                out_spikes.append(S)                         # æŠŠé€™å€‹æ™‚é–“æ­¥çš„ spike å­˜èµ·ä¾†

            return torch.stack(out_spikes, dim=1)            # çµ„æˆ spike train [B, T, C, H, W]
            # âœ³ï¸ SpikingRxï¼šæ¯å±¤ LIF éƒ½æœƒè¼¸å‡ºä¸€ä¸² spike trainï¼Œå‚³çµ¦ä¸‹ä¸€å€‹ blockã€‚
            # âœ³ï¸ ANN æœ€å¾Œä¸€å±¤æœƒæ•´åˆæ‰€æœ‰æ™‚é–“æ­¥çš„ spike ä¾†ç®— LLRã€‚

        elif I.dim() == 3:                                   # [B, T, D] â†’ ç”¨æ–¼æœ€å¾Œå…¨é€£æ¥å±¤
            B, T, D = I.shape
            U = I.new_zeros((B, D))                          # åˆå§‹åŒ–è†œé›»ä½
            out_spikes = []
            for t in range(T):
                It = I[:, t]                                 # ç¬¬ t æ­¥è¼¸å…¥
                U = self.beta * U + (1 - self.beta) * It     # æ›´æ–°è†œé›»ä½
                S = spike_fn(U - self.theta)                 # æ˜¯å¦æ”¾é›»
                U = U - S * self.theta                       # é‡è¨­
                out_spikes.append(S)
            return torch.stack(out_spikes, dim=1)            # [B, T, D]

        else:
            raise ValueError("LIF input must be [B,T,C,H,W] or [B,T,D]")
            # âœ³ï¸ ç¢ºä¿è¼¸å…¥ç¶­åº¦æ­£ç¢ºï¼šSpikingRx çš„è¼¸å…¥ä¸€å®šæœ‰æ™‚é–“æ­¥ Tã€‚

# --------------------------------------------------------
# æ¨¡çµ„å°çµï¼š
# - ArcTanSurrogate æ”¹æˆ TriangularSurrogate â†’ èˆ‡è«–æ–‡ä¸€è‡´ã€‚
# - LIF æ–¹ç¨‹èˆ‡ Î², Î¸ å®Œå…¨å°æ‡‰è«–æ–‡ã€‚
# - forward() çš„æ™‚é–“å±•é–‹å°æ‡‰ SpikingRx ä¸­çš„æ™‚åºæ¼”åŒ–ã€‚
# - æœ€çµ‚è¼¸å‡ºçš„ spike train æœƒé€²å…¥ä¸‹ä¸€å€‹ SEW block æˆ– ANN å±¤ã€‚
# --------------------------------------------------------
```
---

## Key Code Components (with Corresponding Behavior)

| Code Block | Function / Mathematical Behavior | Key Concept |
|-----------|----------------------------------|-------------|
| class TriangularSurrogate | Custom autograd function | Creates a differentiable approximation of the spike function |
| forward() â†’ (x >= 0).to(x.dtype) | Heaviside step: output 1 when membrane potential exceeds threshold | Simulates firing condition |
| backward() â†’ grad = grad_input * (1 - x.abs() / a) * mask / a | Surrogate gradient: passes gradient only near threshold | Prevents gradient explosion or vanishing |
| LIF.forward() â†’ U = Î²*U + (1-Î²)*I[t] | Integration phase | Accumulates input current into membrane potential |
| S = spike_fn(U - Î¸) | Threshold check (Fire) | Outputs a spike if crossing threshold |
| U = U - S*Î¸ | Reset after firing | Resets membrane potential after spike |
| torch.stack(out_spikes, dim=1) | Forms spike train [B,T,C,H,W] | Produces time-series spikes |

---

## Test Code

```python
# src/tests/test_lif.py
import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../models")))

import torch
import matplotlib.pyplot as plt
from lif_neuron import LIF

# --------------------------------------------------------
# å»ºç«‹ LIF æ¨¡çµ„
# --------------------------------------------------------
lif = LIF(beta=0.9, theta=0.5)

# ä¸€ç¶­ç‰¹å¾µæ¸¬è©¦
B, T, D = 1, 20, 1
I = torch.ones(B, T, D) * 1.0 + 0.1 * torch.randn(B, T, D)

print("=== Test A: [B,T,D] ===")
print("Input shape:", I.shape)
out = lif(I)
print("Output shape:", out.shape)
print("Spikes over time:", out.view(T))
print("Total spikes:", int(out.sum().item()))

# --------------------------------------------------------
# é¡å¤–è¨˜éŒ„è†œé›»ä½ U[t]ã€è¼¸å…¥ I[t]ã€spike S[t] ä¸¦ç•«åœ–
# --------------------------------------------------------
U = torch.zeros(B, D)
U_list, S_list, I_list = [], [], []

for t in range(T):
    It = I[:, t]
    U = lif.beta * U + (1 - lif.beta) * It
    S = (U >= lif.theta).float()
    U = U - S * lif.theta

    I_list.append(It.item())
    U_list.append(U.item())
    S_list.append(S.item())

# --------------------------------------------------------
# ç•«åœ–
# --------------------------------------------------------
time = list(range(1, T + 1))
fig, ax1 = plt.subplots(figsize=(8, 4))

ax1.plot(time, I_list, 'k--', label='Input I[t]', alpha=0.5)
ax1.plot(time, U_list, 'b-', label='Membrane Potential U[t]')
ax1.axhline(y=lif.theta.item(), color='r', linestyle=':', label='Threshold Î¸')
ax1.set_xlabel('Time step')
ax1.set_ylabel('U[t], I[t]')
ax1.legend(loc='upper left')

# Spike (ç”¨å¦ä¸€è»¸ç•« 0/1)
ax2 = ax1.twinx()
ax2.scatter(time, S_list, color='orange', label='Spike S[t]', marker='o')
ax2.set_ylabel('Spike (0 or 1)')
ax2.set_ylim(-0.1, 1.2)
ax2.legend(loc='upper right')

plt.title('LIF Neuron Dynamics')
plt.tight_layout()

# --------------------------------------------------------
# å„²å­˜åœ–æª”åˆ° data/
# --------------------------------------------------------
save_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../data/lif_spike_plot.png"))
os.makedirs(os.path.dirname(save_path), exist_ok=True)
plt.savefig(save_path)
plt.close()

print(f"âœ… åœ–ç‰‡å·²å„²å­˜åˆ°: {save_path}")



```
---

## Test Results
<img width="816" height="141" alt="image" src="https://github.com/user-attachments/assets/c85f2f2a-b03c-4421-b040-c3420024dd7f" />

### (1) Text Results
Input dimension: [B, T, D] = [1, 20, 1], representing one neuron over 20 time steps.

Output:
Spikes over time: tensor([... 1., ..., 1., ..., 1.])  
Total spikes: **3**

Meaning:
- Neuron fired 3 times across 20 steps.
- Confirms correct functioning of:
  - Integration
  - Threshold check
  - Reset after firing
- LIF dynamically produces spikes based on input magnitude.

---

### (2) Image Interpretation
<img width="531" height="265" alt="image" src="https://github.com/user-attachments/assets/3f2d7e75-d607-4a04-8fef-42e8fc2977d3" />

- Gray line: input I[t]
- Blue line: membrane potential U[t]
- Red line: threshold Î¸ = 0.5
- Orange dots: firing events

Observations:
- Membrane potential accumulates and crosses threshold â†’ neuron fires.
- After firing, U resets downward â†’ sawtooth pattern.
- Exactly 3 firing events match the text output.

This validates the correct Integrate â†’ Fire â†’ Reset procedure.

---

## Concept Notes
- The LIF firing cycle is three steps: Integrate â†’ Fire â†’ Reset.
- All-zero initial outputs occur when input never crosses Î¸.
- LIF has **no weights**; only hyperparameters Î², Î¸.
- Surrogate gradient only affects **backward pass**, forward output remains binary.
- Output spike train goes to next SEW block.

---

# 2. Conv Module (conv_block.py)

## Module Description
ConvBlock extracts local spatial structure from frequency-domain feature maps.
It is:
- the **first layer** of the SEW block  
- the **only module with trainable weights**

### Position in SEW Block
**Conv** â†’ Norm â†’ LIF â†’ Shortcut

---

## Code
```python
# src/models/conv_block.py

# --------------------------------------------------------
# æ¨¡çµ„ä½ç½®å°æ‡‰ï¼šSpikingRx â†’ SEW-ResNet block â†’ Conv å·ç©å±¤
# --------------------------------------------------------
# é€™å€‹æª”æ¡ˆ conv_block.py å°æ‡‰ SpikingRx è«–æ–‡æ¶æ§‹ä¸­çš„ã€Œå·ç©å‰ç«¯ã€ï¼š
# åœ¨æ¯å€‹ SEW-ResNet block çš„èµ·å§‹ä½ç½®ï¼š
#    Conv â†’ Norm â†’ LIF(spike) â†’ Shortcut
# ConvBlock çš„åŠŸèƒ½æ˜¯èƒå–è¼¸å…¥ç‰¹å¾µï¼Œä¸¦æä¾›é€£çºŒå€¼çµ¦å¾ŒçºŒçš„ Norm å±¤ã€‚
# --------------------------------------------------------

import torch
import torch.nn as nn

# ========================================================
# ä¸€ã€å·ç©æ¨¡çµ„ (ConvBlock)
# ========================================================
# åŠŸèƒ½ï¼š
#   - è² è²¬å°‡è¼¸å…¥ feature map åšç©ºé–“ä¸Šçš„ç‰¹å¾µæå–ã€‚
#   - è¼¸å‡ºä»ç‚ºé€£çºŒå€¼ï¼ˆé spikeï¼‰ï¼Œæœƒäº¤ç”±ä¸‹ä¸€å±¤ SpikeNorm + LIF è™•ç†ã€‚
#   - æ¬Šé‡ä½¿ç”¨ Kaiming Normal åˆå§‹åŒ–ï¼Œä»¥é©é… ReLU-like çš„ spiking å‹•æ…‹ã€‚
# ========================================================

class ConvBlock(nn.Module):
    """
    SpikingRx å·ç©æ¨¡çµ„ï¼š
      å°æ‡‰ SEW-ResNet block çš„ç¬¬ä¸€å±¤å·ç© (Convolution layer)
      ConvBlock = Conv2d + Kaiming åˆå§‹åŒ–
      ä¸åŒ…å« Norm æˆ–å•Ÿå‹•å‡½æ•¸ï¼ˆActivationï¼‰ï¼Œ
      å› ç‚ºé€™éƒ¨åˆ†ç”±å¾ŒçºŒçš„ SpikeNorm + LIF è² è²¬ã€‚
    """

    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, use_bias=True):
        super(ConvBlock, self).__init__()  # åˆå§‹åŒ–çˆ¶é¡åˆ¥ (nn.Module)

        # ----------------------------------------------------
        # å®šç¾©å·ç©å±¤ï¼š
        #   - in_channels:  è¼¸å…¥é€šé“æ•¸
        #   - out_channels: è¼¸å‡ºé€šé“æ•¸ï¼ˆfeature map æ•¸é‡ï¼‰
        #   - kernel_size:  å·ç©æ ¸å¤§å° (3x3)
        #   - stride:       æ­¥å¹…ï¼ˆé è¨­1ï¼‰
        #   - padding:      è£œé›¶ï¼Œç¢ºä¿è¼¸å‡ºå°ºå¯¸ä¸è®Š
        #   - bias:         æ˜¯å¦ä½¿ç”¨åç½®é …
        # ----------------------------------------------------
        self.conv = nn.Conv2d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=kernel_size,
            stride=stride,
            padding=padding,
            bias=use_bias
        )

        # ----------------------------------------------------
        # äºŒã€æ¬Šé‡åˆå§‹åŒ– (Kaiming Normal)
        # ----------------------------------------------------
        # Kaiming Normal æ˜¯ç‚º ReLU é¡æ¿€æ´»å‡½æ•¸è¨­è¨ˆçš„åˆå§‹åŒ–æ–¹æ³•ã€‚
        # åœ¨ SpikingRx ä¸­ï¼ŒLIF å±¤çš„ç™¼ç«è¡Œç‚ºèˆ‡ ReLU é¡ä¼¼ï¼ˆéç·šæ€§æˆªæ–·ï¼‰ï¼Œ
        # å› æ­¤ä½¿ç”¨ç›¸åŒåŸå‰‡å¯ç©©å®šæ¢¯åº¦åˆ†ä½ˆã€‚
        #   - mode='fan_out'ï¼šä½¿è¼¸å‡ºé€šé“æ–¹å·®ä¸€è‡´
        #   - nonlinearity='relu'ï¼šå°æ‡‰ spike çš„å•Ÿå‹•ç‰¹æ€§
        # ----------------------------------------------------
        nn.init.kaiming_normal_(self.conv.weight, mode='fan_out', nonlinearity='relu')

        # è‹¥å•Ÿç”¨ biasï¼Œå°‡åç½®åˆå§‹åŒ–ç‚º 0
        if use_bias:
            nn.init.constant_(self.conv.bias, 0.0)

    # ----------------------------------------------------
    # ä¸‰ã€Forward é‹ç®—æµç¨‹
    # ----------------------------------------------------
    # è¼¸å…¥  : [B, C_in, H, W]
    # è¼¸å‡º  : [B, C_out, H, W]
    # èªªæ˜  :
    #   ConvBlock ä¸åŒ…å« spike é‹ç®—ï¼Œ
    #   åªè² è²¬åœ¨ç©ºé–“ç¶­åº¦ä¸Šå·ç©è¼¸å…¥ç‰¹å¾µï¼Œ
    #   ä¸¦å°‡è¼¸å‡ºäº¤ç”±ä¸‹ä¸€å±¤ Norm + LIF è™•ç†ã€‚
    # ----------------------------------------------------
    def forward(self, x):
        out = self.conv(x)  # å·ç©é‹ç®—
        return out          # å›å‚³é€£çºŒç‰¹å¾µåœ– (éäºŒå€¼åŒ–)

# --------------------------------------------------------
# æ¨¡çµ„å°çµï¼š
# - ConvBlock = å–®ç´”å·ç© + Kaiming åˆå§‹åŒ–
# - ä¸åŒ…å« LIF æˆ–æ­£è¦åŒ–ï¼Œå¾ŒçºŒç”± SpikeNorm + LIF è™•ç†
# - å°æ‡‰ SEW-ResNet block çš„ç¬¬ä¸€æ­¥ï¼šã€Œç‰¹å¾µæå–ã€
# --------------------------------------------------------


```


---

## Key Components

| Code Block | Function / Math Behavior | Key Concept |
|-----------|---------------------------|-------------|
| self.conv = nn.Conv2d(...) | Defines convolution kernel | Corresponds to Y = W * X + b |
| nn.init.kaiming_normal_(...) | Weight initialization | Suitable for LIF/ReLU-like activations |
| forward() â†’ self.conv(x) | Forward convolution | Produces feature map [B,C_out,H,W] |

---

## Test Code
```python
# src/tests/test_conv.py
import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../models")))

import torch
import matplotlib.pyplot as plt
from conv_block import ConvBlock

# --------------------------------------------------------
# å»ºç«‹ä¸¦æ¸¬è©¦ ConvBlock
# --------------------------------------------------------
conv = ConvBlock(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)
x = torch.randn(2, 3, 32, 32)   # æ¨¡æ“¬è¼¸å…¥ [B,C,H,W]

print("=== ConvBlock Forward Test ===")
print("Input shape :", x.shape)
y = conv(x)
print("Output shape:", y.shape)
print(f"Output sample (mean,std): {y.mean().item():.4f}, {y.std().item():.4f}")

# --------------------------------------------------------
# ä¸€ã€è¦–è¦ºåŒ–å·ç©æ ¸ (filters)
# --------------------------------------------------------
weights = conv.conv.weight.data.clone().detach().cpu()
out_channels, in_channels, kh, kw = weights.shape
print(f"Conv filters shape: {weights.shape}")

fig, axes = plt.subplots(out_channels, in_channels, figsize=(in_channels*2, out_channels*2))
fig.suptitle("Conv Filters", fontsize=14)

for i in range(out_channels):
    for j in range(in_channels):
        ax = axes[i, j] if out_channels > 1 else axes[j]
        w = weights[i, j].numpy()
        ax.imshow(w, cmap='bwr', interpolation='nearest')
        ax.axis('off')
        ax.set_title(f"f{i}-ch{j}")
plt.tight_layout()

save_path_filters = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../data/conv_filters.png"))
os.makedirs(os.path.dirname(save_path_filters), exist_ok=True)
plt.savefig(save_path_filters)
plt.close()
print(f"âœ… å·ç©æ ¸åœ–å·²å„²å­˜åˆ°: {save_path_filters}")

# --------------------------------------------------------
# äºŒã€è¦–è¦ºåŒ–å·ç©å¾Œçš„ç‰¹å¾µåœ– (feature maps)
# --------------------------------------------------------
with torch.no_grad():
    feature_maps = conv(x)[0]  # å–ç¬¬1ç­†è¼¸å‡º [C,H,W]

fig, axes = plt.subplots(1, feature_maps.shape[0], figsize=(feature_maps.shape[0]*2, 2))
fig.suptitle("Output Feature Maps", fontsize=14)

for i, ax in enumerate(axes):
    fm = feature_maps[i].detach().cpu().numpy()
    ax.imshow(fm, cmap='viridis')
    ax.axis('off')
    ax.set_title(f"Map {i}")
plt.tight_layout()

save_path_fm = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../data/conv_featuremaps.png"))
plt.savefig(save_path_fm)
plt.close()
print(f"âœ… ç‰¹å¾µåœ–å·²å„²å­˜åˆ°: {save_path_fm}")

```


---

## Test Results
<img width="561" height="155" alt="image" src="https://github.com/user-attachments/assets/87d06f51-d592-4730-8ac9-653952e9d82e" />

### (1) Text Results
- Input channels: 3  
- Output channels: 8  
- Spatial size remains 32Ã—32  

Output stats:
- Mean â‰ˆ 0  
- Std â‰ˆ 0.9  

Interpretation:
- Features stable
- Kaiming initialization functioning
- Forward pass successful

---

### (2) Image Results

<img width="194" height="516" alt="image" src="https://github.com/user-attachments/assets/a0bb9993-b8e7-4406-a716-3a52481d1ad6" /><img width="691" height="170" alt="image" src="https://github.com/user-attachments/assets/b798fd9b-b56f-4a1d-8e1c-d5a425ce59f1" /><img width="704" height="170" alt="image" src="https://github.com/user-attachments/assets/3e1d2eef-5aa0-45d9-850e-fc642ed136c4" />

**above Image â€” Conv Filters**
- Each square is one 3Ã—3 kernel
- Colormap bwr (red = positive, blue = negative)
- Rows correspond to same filter across input channels (f0-ch0, f0-ch1, f0-ch2)
- Mix of symmetry + randomness â†’ good diverse sensitivity

**below Image â€” Feature Maps**
- 8 maps (Map 0~7), each 32Ã—32
- Color intensity = activation strength
- Even distribution â†’ no collapse

---

## Concept Notes
- ConvBlock has **no activation**; LIF provides nonlinearity.
- padding=1 preserves spatial alignment with shortcut.
- Visualizing filters helps understand sensitivity.
- Tests overwrite previous images to only keep newest.

---

# 3. Norm Module (norm_layer.py)

## Module Description
SpikeNorm normalizes convolution output to stabilize membrane potential before LIF.

Key difference from BatchNorm:
- **Does not average across time**
- Preserves temporal sparsity

### Position in SEW Block
Conv â†’ **Norm** â†’ LIF â†’ Shortcut

---

## Code
```python
# src/models/norm_layer.py

# --------------------------------------------------------
# æ¨¡çµ„ä½ç½®å°æ‡‰ï¼šSpikingRx â†’ SEW-ResNet block â†’ SpikeNorm æ­£è¦åŒ–å±¤
# --------------------------------------------------------
# æœ¬æª”æ¡ˆå°æ‡‰ SpikingRx è«–æ–‡ä¸­çš„ã€ŒSpikeNormã€æ¨¡çµ„ã€‚
# åœ¨æ¯å€‹ SEW-ResNet block ä¸­ï¼Œå…¶çµæ§‹ç‚ºï¼š
#       Conv â†’ Norm â†’ LIF(spike)
# SpikeNorm çš„ç›®çš„ï¼š
#   - ç©©å®š feature map çš„æ•¸å€¼ç¯„åœï¼Œé¿å… LIF è†œé›»ä½çˆ†ç‚¸æˆ–é•·æœŸä¸æ”¾é›»ã€‚
#   - å°æ¯å€‹é€šé“ (channel) ç¨ç«‹åšç©ºé–“ç¶­åº¦æ­£è¦åŒ–ã€‚
#   - ä¸è·¨æ™‚é–“ (T)ï¼Œä¿ç•™æ™‚åºç¨€ç–æ€§ã€‚
# --------------------------------------------------------

import torch
import torch.nn as nn

# ========================================================
# ä¸€ã€SpikeNorm æ¨¡çµ„
# ========================================================
# åŠŸèƒ½ï¼š
#   - å°æ¯å€‹é€šé“åœ¨ç©ºé–“ç¶­åº¦ (H, W) ä¸Šåšæ¨™æº–åŒ–ã€‚
#   - åœ¨æ™‚åºç¶­åº¦ (T) ä¸Šé€æ­¥è™•ç†ï¼Œä¸æ··åˆä¸åŒæ™‚é–“æ­¥çš„çµ±è¨ˆã€‚
#   - é¿å…åœ¨ SNN ä¸­ç ´å£æ™‚åºç›¸é—œæ€§ã€‚
#   - è¼¸å‡ºç¶­åº¦èˆ‡è¼¸å…¥ç›¸åŒã€‚
# ========================================================

class SpikeNorm(nn.Module):
    """
    SpikeNorm å±¤ï¼š
      å°è¼¸å…¥ feature map é€²è¡Œã€Œé€šé“å±¤ç´šã€çš„æ¨™æº–åŒ–ï¼Œ
      å°‡æ¯å€‹é€šé“çš„å‡å€¼èª¿æ•´ç‚º 0ã€è®Šç•°æ•¸èª¿æ•´ç‚º 1ã€‚
      ç›¸ç•¶æ–¼ BatchNorm2dï¼Œä½†ï¼š
        - ä¸ä½¿ç”¨ batch running mean/varã€‚
        - ä¸è·¨æ™‚é–“ç¶­åº¦ (T) æ··åˆã€‚
      å…¶ç›®çš„åœ¨æ–¼è®“ LIF å±¤æ¥æ”¶åˆ°ç©©å®šåˆ†å¸ƒçš„è¼¸å…¥ï¼Œé˜²æ­¢é–¾å€¼è§¸ç™¼è¡Œç‚ºä¸ç©©ã€‚
    """

    def __init__(self, num_channels, eps=1e-5, momentum=0.1, affine=True):
        super(SpikeNorm, self).__init__()

        # ----------------------------------------------------
        # å»ºç«‹ BatchNorm2dï¼ˆä½†å°‡è¢«ç”¨ä½œ SpikeNormï¼‰
        # ----------------------------------------------------
        # PyTorch çš„ BatchNorm2d æä¾›äº†ï¼š
        #   x' = (x - Î¼) / âˆš(ÏƒÂ² + Îµ) * Î³ + Î²
        # å…¶ä¸­ Î¼, ÏƒÂ² ç‚ºé€šé“çš„å‡å€¼èˆ‡è®Šç•°æ•¸ï¼›
        # Î³, Î² ç‚ºå¯å­¸ç¿’çš„ç¸®æ”¾èˆ‡å¹³ç§»åƒæ•¸ï¼ˆè‹¥ affine=Trueï¼‰ã€‚
        # SpikeNorm æ¡ç”¨ç›¸åŒé‹ç®—ï¼Œä½†ä¸æ›´æ–°å…¨åŸŸçµ±è¨ˆï¼Œ
        # ä¸¦å°æ¯å€‹æ™‚é–“æ­¥ç¨ç«‹åŸ·è¡Œã€‚
        # ----------------------------------------------------
        self.bn = nn.BatchNorm2d(
            num_features=num_channels,  # é€šé“æ•¸ C
            eps=eps,                    # é¿å…é™¤ä»¥ 0
            momentum=momentum,          # æ§åˆ¶çµ±è¨ˆæ›´æ–°ï¼ˆé›–ç„¶ä¸æœƒåœ¨é€™è£¡ç”¨åˆ°ï¼‰
            affine=affine               # æ˜¯å¦ä½¿ç”¨å¯å­¸åƒæ•¸ Î³, Î²
        )

    # ----------------------------------------------------
    # äºŒã€Forward å‚³é
    # ----------------------------------------------------
    # æ”¯æ´å…©ç¨®è¼¸å…¥ï¼š
    #   [B, C, H, W]ï¼šå–®ä¸€æ™‚é–“æ­¥ï¼ˆéœæ…‹å½±åƒæˆ– feature mapï¼‰
    #   [B, T, C, H, W]ï¼šå¤šæ™‚é–“æ­¥è¼¸å…¥ï¼ˆspike æ™‚åºç‰¹å¾µï¼‰
    # æ¯å€‹æ™‚é–“æ­¥ç¨ç«‹åšé€šé“æ­£è¦åŒ–ã€‚
    # ----------------------------------------------------
    def forward(self, x):
        """
        è¼¸å…¥  : [B, C, H, W] æˆ– [B, T, C, H, W]
        è¼¸å‡º  : åŒå°ºå¯¸å¼µé‡ï¼Œç¶“éæ¯é€šé“æ¨™æº–åŒ–
        """
        if x.dim() == 5:
            # ------------------------------------------------
            # è‹¥è¼¸å…¥æœ‰æ™‚é–“ç¶­åº¦ [B, T, C, H, W]
            # å°æ¯å€‹æ™‚é–“æ­¥åˆ†åˆ¥æ­£è¦åŒ–ï¼ˆä¸è·¨æ™‚é–“ï¼‰
            # ------------------------------------------------
            B, T, C, H, W = x.shape
            out = []
            for t in range(T):
                # å°æ™‚é–“æ­¥ t çš„è³‡æ–™åŸ·è¡Œ BatchNorm2d
                out_t = self.bn(x[:, t, :, :, :])
                out.append(out_t)
            return torch.stack(out, dim=1)

        elif x.dim() == 4:
            # ------------------------------------------------
            # è‹¥è¼¸å…¥æ˜¯å–®ä¸€æ™‚é–“æ­¥ [B, C, H, W]
            # ç›´æ¥åŸ·è¡Œ BatchNorm2d
            # ------------------------------------------------
            return self.bn(x)

        else:
            raise ValueError("SpikeNorm input must be 4D [B,C,H,W] or 5D [B,T,C,H,W]")

# --------------------------------------------------------
# æ¨¡çµ„å°çµï¼š
# - SpikeNorm æ˜¯ SpikingRx çš„æ™‚åºé€šé“æ­£è¦åŒ–å±¤ã€‚
# - æ¯å€‹æ™‚é–“æ­¥ç¨ç«‹æ­£è¦åŒ– â†’ ä¸ç ´å£ spike æ™‚é–“ç¨€ç–æ€§ã€‚
# - è¼¸å…¥èˆ‡è¼¸å‡ºå°ºå¯¸ä¸€è‡´ã€‚
# - å°æ‡‰ SEW-ResNet block çš„ç¬¬äºŒéšæ®µï¼ˆConv å¾Œã€LIF å‰ï¼‰ã€‚
# --------------------------------------------------------
```


---

## Key Components

| Code Block | Function / Behavior | Key Concept |
|-----------|----------------------|-------------|
| self.bn = nn.BatchNorm2d(C) | Defines normalization per channel | Normalizes spatial distribution |
| forward(): dimension check | Supports [B,C,H,W] and [B,T,C,H,W] | Handles time-series inputs |
| for each t: self.bn(x[:,t]) | Normalizes each time step independently | Keeps temporal independence |
| stack along dim=1 | Reconstructs [B,T,C,H,W] | Forms full time series |

---

## Test Code
```python
# src/tests/test_norm.py
import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../models")))

import torch
from norm_layer import SpikeNorm

# --------------------------------------------------------
# æ¸¬è©¦ SpikeNorm æ¨¡çµ„
# --------------------------------------------------------
norm = SpikeNorm(num_channels=8)
x = torch.randn(2, 8, 32, 32)     # å–®æ™‚é–“æ­¥è¼¸å…¥
x_seq = torch.randn(2, 5, 8, 32, 32)  # å¤šæ™‚é–“æ­¥è¼¸å…¥

print("=== SpikeNorm Forward Test ===")

# å–®æ­¥æ¸¬è©¦
y = norm(x)
print("Input shape :", x.shape)
print("Output shape:", y.shape)
print("Output mean :", y.mean().item(), "std:", y.std().item())

# å¤šæ­¥æ¸¬è©¦
y_seq = norm(x_seq)
print("\n=== SpikeNorm Temporal Test ===")
print("Input shape :", x_seq.shape)
print("Output shape:", y_seq.shape)
print("Mean/std at t=0:", y_seq[:,0].mean().item(), y_seq[:,0].std().item())
print("Mean/std at t=4:", y_seq[:,4].mean().item(), y_seq[:,4].std().item())

import matplotlib.pyplot as plt

# --------------------------------------------------------
# é¡å¤–è¦–è¦ºåŒ–ï¼šé¡¯ç¤ºæ­£è¦åŒ–å‰å¾Œçš„åˆ†å¸ƒ
# --------------------------------------------------------
x_before = x_seq.detach().cpu().numpy().ravel()      # åŸå§‹è¼¸å…¥åˆ†å¸ƒ
x_after = y_seq.detach().cpu().numpy().ravel()       # æ­£è¦åŒ–å¾Œåˆ†å¸ƒ

plt.figure(figsize=(6, 4))
plt.hist(x_before, bins=80, alpha=0.5, label='Before Norm')
plt.hist(x_after, bins=80, alpha=0.5, label='After Norm')
plt.legend()
plt.title("SpikeNorm Normalization Effect")
plt.xlabel("Value")
plt.ylabel("Frequency")

save_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../data/spikenorm_distribution.png"))
os.makedirs(os.path.dirname(save_path), exist_ok=True)
plt.tight_layout()
plt.savefig(save_path)
plt.close()

print(f"âœ… åˆ†å¸ƒåœ–å·²å„²å­˜åˆ°: {save_path}")

```

---

## Test Results
<img width="491" height="178" alt="image" src="https://github.com/user-attachments/assets/cb7da30d-b530-4bcf-87ec-7f66e4b7bc54" />


### (1) Text Results
SpikeNorm normalizes data to:
- mean = 0  
- std = 1  

Works for single-step and time-series inputs.

Meaning:
- Temporal independence preserved  
- No drift  
- Stable inputs for LIF

---

### (2) Histogram Results
<img width="369" height="246" alt="image" src="https://github.com/user-attachments/assets/44c7ebe4-2e0a-43dc-867b-c79ab5f96046" />


Observations:
- Before/after histograms overlap near 0
- Range â‰ˆ Â±4
- Distribution becomes more concentrated and stable

Interpretation:
- SpikeNorm ensures consistent scaling before LIF
- Helps LIF threshold fire properly

---
# 4. SEW Block Module (sew_block.py)

## Module Description
SEW (Spike-Element-Wise) Block is the main structural unit of SpikingRx.
It integrates convolution, normalization, LIF spiking, and residual (shortcut) connections.
This corresponds to the SEW-ResNet block in the paper.

<img width="428" height="64" alt="image" src="https://github.com/user-attachments/assets/67e6b374-0d5a-4047-b7b0-faf1eb3bff8b" />

## Code
```python
# src/models/sew_block.py

import torch
import torch.nn as nn

from .conv_block import ConvBlock
from .norm_layer import SpikeNorm
from .lif_neuron import LIF


class SEWBlock(nn.Module):
    """
    Spike-Element-Wise (SEW) Block æ¨¡çµ„

    ä¸»æ”¯è·¯ (main path):
        X[t] â†’ Conv â†’ Norm â†’ LIF â†’ main_out[t]

    æ·å¾‘æ”¯è·¯ (shortcut):
        X[t] â†’ (Identity æˆ– 1Ã—1 Conv) â†’ shortcut_out[t]

    æœ€çµ‚è¼¸å‡º:
        Y[t] = main_out[t] + shortcut_out[t]

    è¼¸å…¥:  [B, T, C_in, H, W]
    è¼¸å‡º:  [B, T, C_out, H, W]
    """

    def __init__(self, in_channels, out_channels, stride=1):
        super(SEWBlock, self).__init__()

        # ä¸»æ”¯è·¯
        self.conv = ConvBlock(in_channels, out_channels, stride=stride)
        self.norm = SpikeNorm(out_channels)
        self.lif = LIF(theta=0.2)  # ä½¿ç”¨ [B,T,C,H,W] æ ¼å¼

        # æ·å¾‘åˆ†æ”¯ï¼šè‹¥ç¶­åº¦ä¸åŒéœ€ç”¨ 1Ã—1 Conv å°é½Š
        if in_channels != out_channels or stride != 1:
            self.shortcut = nn.Conv2d(
                in_channels, out_channels, kernel_size=1, stride=stride
            )
        else:
            self.shortcut = nn.Identity()

    def forward(self, x):
        """
        x: [B, T, C, H, W]
        return: [B, T, C_out, H, W]
        """
        B, T, C, H, W = x.shape
        outputs = []

        for t in range(T):

            xt = x[:, t]                          # [B,C,H,W]
            main = self.conv(xt)                  # Conv
            main = self.norm(main)                # Norm

            # LIF éœ€è¦ 5 ç¶­ï¼Œå› æ­¤åŠ å› T=1 ç¶­
            main = self.lif(main.unsqueeze(1))    # [B,1,C,H,W]
            main = main[:, 0]                     # ç§»é™¤æ™‚é–“ç¶­åº¦ â†’ [B,C,H,W]

            sc = self.shortcut(xt)                # Shortcut

            outputs.append(main + sc)

        return torch.stack(outputs, dim=1)        # [B,T,C_out,H,W]

```

## Key Components (with Corresponding Behavior)

Code Block | Function / Mathematical Behavior | Key Concept
---------- | -------------------------------- | -----------
self.conv_block = ConvBlock(...) | Main branch convolution | Extracts primary features
self.norm = SpikeNorm(...) | Normalization | Stabilizes activation scale
self.lif = LIF(...) | LIF spiking | Converts features to spikes
if in_ch != out_ch: shortcut = Conv2d(1x1) | Channel alignment | Ensures equal dimensions for addition
y = main + shortcut | Residual fusion | Gradient splits automatically

## Test Code
```python
# src/tests/test_sew.py

import sys, os
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.append(ROOT)

import torch
from models.sew_block import SEWBlock


# --------------------------------------------------------
# Helper â†’ print 2D slice (8Ã—8)
# --------------------------------------------------------
def print_matrix(title, x, max_h=8, max_w=8):
    print(f"\n--- {title} ({max_h}x{max_w}) ---")
    print(x[:max_h, :max_w])


# --------------------------------------------------------
# Create SEW block
# --------------------------------------------------------
in_channels = 4
out_channels = 8
sew = SEWBlock(in_channels, out_channels)


# --------------------------------------------------------
# Prepare fake OFDM-like data [B,T,C,H,W]
# --------------------------------------------------------
B, T, C, H, W = 1, 5, in_channels, 32, 32
x = torch.randn(B, T, C, H, W)

print("\n======================================")
print("    ORIGINAL OFDM-LIKE INPUT SLICES    ")
print("======================================")
for t in range(4):
    for c in range(4):
        print_matrix(f"Input t={t}, c={c}", x[0, t, c])


# --------------------------------------------------------
# Manual SEWBlock debug: Conv / Norm / LIF / Shortcut
# --------------------------------------------------------
conv = sew.conv
norm = sew.norm
lif  = sew.lif
shortcut_layer = sew.shortcut

print("\n======================================")
print("          DEBUG: CONV OUTPUT          ")
print("======================================")

conv_out_all = []
for t in range(4):
    xt = x[0, t].unsqueeze(0)
    conv_out = conv(xt)
    conv_out_all.append(conv_out)

    for c in range(4):
        print_matrix(f"Conv t={t}, c={c}", conv_out[0, c])


print("\n======================================")
print("          DEBUG: NORM OUTPUT          ")
print("======================================")

norm_out_all = []
for t in range(4):
    norm_out = norm(conv_out_all[t])
    norm_out_all.append(norm_out)

    for c in range(4):
        print_matrix(f"Norm t={t}, c={c}", norm_out[0, c])


print("\n======================================")
print("           DEBUG: LIF SPIKES          ")
print("======================================")

lif_out_all = []
for t in range(4):
    # LIF expects [B,T,C,H,W]
    lif_input = norm_out_all[t].unsqueeze(1)
    lif_out = lif(lif_input)       # â†’ [B,1,C,H,W]
    spikes = lif_out[:, 0]
    lif_out_all.append(spikes)

    for c in range(4):
        print_matrix(f"LIF spikes t={t}, c={c}", spikes[0, c])


print("\n======================================")
print("        DEBUG: SHORTCUT OUTPUT        ")
print("======================================")

shortcut_all = []
for t in range(4):
    xt = x[0, t].unsqueeze(0)
    sc = shortcut_layer(xt)
    shortcut_all.append(sc)

    for c in range(4):
        print_matrix(f"Shortcut t={t}, c={c}", sc[0, c])


print("\n======================================")
print("        FINAL SEW OUTPUT SLICES       ")
print("======================================")

# Final output must match SEW forward behavior
final_output_all = []
for t in range(4):
    y = lif_out_all[t] + shortcut_all[t]
    final_output_all.append(y)

    for c in range(4):
        print_matrix(f"SEW output t={t}, c={c}", y[0, c])


print("\nAll debug slices printed successfully. ğŸš€")

```

## Test Results
<img width="636" height="428" alt="image" src="https://github.com/user-attachments/assets/5d42e8d7-c1be-4145-9d7b-0e5e4d2bb764" />


(1) Text Results

Two scenarios were tested:

1. Identity Shortcut (input and output channels equal)
Input shape: [2, 5, 4, 32, 32]
Output shape: [2, 5, 4, 32, 32]
Mean: 0.0023
Std: 1.0016
Interpretation: Dimensions match; output stable.

2. Convolution Shortcut (input and output channels differ)
Input shape: [2, 5, 4, 32, 32]
Output shape: [2, 5, 8, 32, 32]
Mean: 0.0247
Std: 0.5712
Interpretation: 1x1 convolution aligns channels; output is reasonable.

Spike activity over time:
tensor([-0.0057, -0.0166, 0.0308, 0.0088, -0.0061])

This shows temporal stability and sparse firing.

(2) Image Results
<img width="461" height="231" alt="image" src="https://github.com/user-attachments/assets/afb1ce23-cda1-4d31-a192-374c32614a68" />

A line plot shows mean spike activity per time step:
- Higher activity in steps 2 and 3.
- Near-zero in other steps.
This indicates temporal sparsity and stability.

## Concept Notes

Why residual addition does not mix incorrectly:
PyTorch autograd's AddBackward node divides the gradient into two paths:

grad_output -> main
grad_output -> shortcut

This allows both paths to receive gradients properly.

Shortcut benefits:
- Stabilizes gradient flow.
- Preserves original representation.
- Helps training convergence.

Monitoring recommendations:
- Output mean/std ideally around 0.6 to 1.0
- Spike activity oscillation around +-0.005
- Channel variance indicates shortcut effectiveness

# 5. Current Progress Summary

Module | Status | Function
------ | ------ | --------
lif_neuron.py | Completed | Temporal spiking core
conv_block.py | Completed | Feature extraction
norm_layer.py | Completed | Time-independent normalization
sew_block.py | Completed | Residual and spiking integration

All core SEW-ResNet front-end modules are fully implemented and validated.

# 6. Overall Understanding and Next Steps

The front half of the SpikingRx model is complete:
Conv -> Norm -> LIF -> Shortcut (repeated across SEW blocks)

All modules align with the SpikingRx paper:
- Convolution uses Kaiming initialization
- SpikeNorm stabilizes membrane potentials
- LIF implements temporal dynamics with Integrate-Fire-Reset
- SEW blocks fuse residual and main paths

# Recommended Next Steps

1. Implement spikingrx_model.py
   - Stack multiple SEW blocks
   - Add ANN readout to generate LLR output

2. Build higher-level test (test_spikingrx.py)
   - Full-model forward pass verification

3. Analytical suggestions
   - Analyze spike density and temporal distribution
   - Evaluate effect of beta and theta on firing rate
   - Visualize spike activity per layer
